# alpha2048

A Deep Reinforcement Learning method easily applicable to randomized problems could be generalized to solving challenging real world problems with changing environments such as autonomous vehicles and financial strategies. Games with random elements can be used as test environments for such AI, but are often solved using specialized heuristics that are not generally applicable. In this paper, we apply vanilla Policy Gradients on the game 2048, examining both different network complexities and a number of reward functions with differing degrees of specialization to find the optimal Deep Reinforcement Learning approach for such a problem. We observe that all agents improve and do outperform randomness but are far behind human ability, and that complex networks and specialized reward functions do not improve results. Conclusively, we highlight the poor robustness of Policy Gradients as a barrier for training on randomized tasks and call for testing of more cautious approaches such as Trust Region Policy Optimization and for a more systematic hyper-parameter search.